{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ProfAI/nlp00/blob/master/6%20-%20Sentiment%20Analysis/classifier_sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SD7bU28fId0p"
   },
   "source": [
    "# Creare un classificatore con Scikit-learn\n",
    "In questo notebook vedremo come creare un classificatore utilizzando scikit-learn. Lo scopo del nostro classificatore sarà quello di eseguire la **sentiment analysis** sull'IMDB movie reviews dataset, per classificare le recensioni di film come negative o positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vMyeO5ZJIh7x"
   },
   "source": [
    "## Procuriamoci il dataset\n",
    "Cominciamo scaricando il dataset, esegui la cella di codice qui sotto se sei su Google Colab o se hai wget installato sul tuo computer, altrimenti puoi scaricare il dataset da [questo link](http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "colab_type": "code",
    "id": "tDQc-LaEgCyH",
    "outputId": "a802ca18-4d45-4a29-94d8-6f4770430541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\r\n"
     ]
    }
   ],
   "source": [
    "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hG9mWOxNGYUM"
   },
   "source": [
    "L'archivio è compresso in formato tar.gz, esegui la cella di codice qui sotto se sei su Colab o hai l'utility tar installata sul tuo PC (solitamente è installata di base su Linux/OsX) se sei su Windows puoi usare [7-zip](https://www.7-zip.org/) (può essere che anche winrar vada bene per estrarlo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gdKW07o6hErd"
   },
   "outputs": [],
   "source": [
    "!tar -xzf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pdxn7YG1G-Wb"
   },
   "source": [
    "Se abbiamo estratto il dataset adesso avremo una cartella aclImdb con dentro diversi file e altre due cartelle, una con le recensioni per l'addestramento e una con le recensioni per il test. Il dataset ci fornisce il testo di ogni recensione, ognuna in un file txt differente, organizzate in cartelle corrispondenti al sentiment positivo/negativo.\n",
    "<br>\n",
    "Oltre a questo ci vengono forniti dei file .feat con le recensioni già codificate utilizzando il **bag of words**, cominciamo utilizzando questi file per creare un classificatore, dopo vedremo come codificare noi stessi le recensioni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-c7lE6SNs8ka"
   },
   "source": [
    "## Metodo facile: Usiamo le features precalcolate\n",
    "**ATTENZIONE** se vuoi provare ad utilizzare i file .feat non puoi utilizzare Google Colab, dato che la RAM messa a disposizione non è sufficiente, se preferisci passa direttamente al metodo 2.\n",
    "\n",
    "Le features sono codificate in formato LIBSVM, un formato utilizzato per codificare matrici sparse. Ogni riga rappresenta una recensione, il primo numero di ogni riga corrisponde al sentiment da 1 (molto scarso) a 9 (molto buono). Gli altri valori sono in formato chiave:valore, dove la chiave è l'indice della parola all'interno del dizionario (il file imdb.vocab) e il valore è il numero di volte che la parola in questione compare all'interno della frase.\n",
    "<br>\n",
    "Definiamo una funzione che partendo da questo file ci permetta di ottenere la matrice che ha per ogni riga la rappresentazione bag of words di ogni recensione e il vettore con il sentiment.\n",
    "<br>\n",
    "Per caricare un file in formato LIBSVM possiamo usare la funzione *load_svmlight_file* di sklearn, il suo output è una tupla con all'indice 0 la matrice sparsa e all'indice 1 il vettore con i target. Utilizziamo un parametro max_features per limitare il numero di parole da tenere come features, tra quelle più frequenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D8J85a1ms8ke"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "def get_xy(file, max_features=5000, binary=True):\n",
    "        \n",
    "    DICTSIZE = 89522\n",
    "    \n",
    "    # Le parole nel dizionario sono 89522\n",
    "    # se viene inserito un numero maggiore\n",
    "    # come dimensione del dizionario, correggiamolo\n",
    "        \n",
    "    if(max_features>DICTSIZE):\n",
    "        max_features = DICTSIZE\n",
    "    \n",
    "    dataset = load_svmlight_file(file)\n",
    "    X = dataset[0].todense() # .todense() serve per convertire la matrice sparsa in densa\n",
    "    \n",
    "    X = np.array(X[:,:max_features])\n",
    "    y = dataset[1]\n",
    "    \n",
    "    if(binary):\n",
    "        y[y<=5] = 0 # se il punteggio è minore o uguale a 5 è una recensione negativa\n",
    "        y[y>5] = 1 # se il punteggio è maggiore di 5 è una recensione positiva\n",
    "        \n",
    "    return (X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LzEZoj_VJnQZ"
   },
   "source": [
    "Utilizziamo la funzione per creare gli array per l'addestramento e il test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r-b6_bSiK1TJ"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_xy(\"aclImdb/train/labeledBow.feat\")\n",
    "X_test, y_test = get_xy(\"aclImdb/test/labeledBow.feat\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MWzQeJBEJsiP"
   },
   "source": [
    "Standardizziamo il dataset utilizzando la classe *StandardScaler* di sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XiFrYliBs8kk"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2aCcPVCJztD"
   },
   "source": [
    "Creiamo il nostro modello di regressione logistica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0ExqABCs8ko",
    "outputId": "c98c2d2c-40f6-4044-a0a1-e12e300e549e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=0.001) # C ci serve per ridurre l'overfitting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CwjKt_YwJ2lR"
   },
   "source": [
    "Verifichiamo il risultato calcolando accuracy e log loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rMPXYYH7s8kq",
    "outputId": "4325c955-f83d-46d6-e3ac-843ab838bb99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 0.9440 - Train Loss 0.1978\n",
      "Test Accuracy 0.8776 - Test Loss 0.3126\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "train_pred = lr.predict(X_train) \n",
    "train_pred_proba = lr.predict_proba(X_train)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_pred)\n",
    "train_loss = log_loss(y_train, train_pred_proba)\n",
    "\n",
    "test_pred = lr.predict(X_test)\n",
    "test_pred_proba = lr.predict_proba(X_test)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, test_pred)\n",
    "test_loss = log_loss(y_test, test_pred_proba)\n",
    "\n",
    "print(\"Train Accuracy %.4f - Train Loss %.4f\" % (train_accuracy, train_loss)) \n",
    "print(\"Test Accuracy %.4f - Test Loss %.4f\" % (test_accuracy, test_loss)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kgSwfbcAs8kt"
   },
   "source": [
    "## Metodo difficile: Estraiamo le features\n",
    "Adesso proviamo a fare lo stesso, ma questa volta partendo dalle recensioni e codificandole noi stessi utilizzando il bag of words. Definiamo una funzione per leggere tutte le recensioni da tutti i files per poi ritornarle insieme al target corrispondente. Prima di ritornarle mescoliamo il dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vt6648bEs8kw"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def get_xy(files_path, labels=[\"pos\",\"neg\"]):\n",
    "    \n",
    "    \n",
    "    label_map = {labels[0]:1, labels[1]:0}\n",
    "    \n",
    "    reviews = []\n",
    "    y = []\n",
    "    \n",
    "    for label in labels:\n",
    "      path = files_path+label\n",
    "      for file in listdir(path):\n",
    "        review_file = open(path+\"/\"+file)\n",
    "        review = review_file.read()    \n",
    "        \n",
    "        reviews.append(review)\n",
    "        y.append(label_map[label])\n",
    "        \n",
    "    # la funzione shuffle di sklearn ci permette di\n",
    "    # mescolare più array allo stesso modo\n",
    "    \n",
    "    reviews, y = shuffle(reviews,y)\n",
    "    \n",
    "    return(reviews,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4KxQkTHMKxY9"
   },
   "source": [
    "Utilizziamo la funzione per ottenere le recensioni e il target in due liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "NHlX51rNxU38",
    "outputId": "b2f23132-660c-4266-d549-ec5b1bed307d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prima recensione del set di test\n",
      "<br /><br />Won't be long on this movie. The first half an hour was one of the most boring i have had to face since i've started watching movies. The story didn't advanced, nothing was explained about any of the characters. It felt like a non-movie. (A lot of people had already left the audience at this point).<br /><br />A lot of the scene were totally unjustified and unexplained.<br /><br />The director should have studied film a bit more to know that each sequence, each scene, has to make the story go forward. He never did that.<br /><br />The supposedly funny moments were contrived, and only a few people laughed (people with a weird sense of humor, i guess).<br /><br />Prize of the Jury in Cannes 2002.....don't know what the jury was thinking about....probably the \"politicly correct effect\".<br /><br />I would have loved to love it, the disappointment was therefore even bigger.<br /><br />You have to see it to believe it. But wait for the video.\n",
      "Sentimeny: 0\n"
     ]
    }
   ],
   "source": [
    "reviews_train, y_train = get_xy(\"aclImdb/train/\")\n",
    "reviews_test, y_test = get_xy(\"aclImdb/test/\")\n",
    "\n",
    "print(\"Prima recensione del set di test\")\n",
    "print(reviews_test[0])\n",
    "print(\"Sentimeny: %d\" % y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l67_N8cVLL13"
   },
   "source": [
    "Adesso codifichiamo le recensioni, possiamo eseguire il bag of words con scikit-learn utilizzando la classe *CountVectorizer*, tramite il parametro *max_fetures* possiamo controllare il numero totale di features (e quindi di parole) da tenere, nel nostro caso teniamo soltanto le 5000 parole più frequenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MffwVvQ3zweG",
    "outputId": "4082e85e-88f1-4475-83ee-ca759f1abf25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5000)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow = CountVectorizer(max_features=5000)\n",
    "\n",
    "bow_train = bow.fit_transform(reviews_train)\n",
    "bow_test = bow.transform(reviews_test)\n",
    "\n",
    "X_train = bow_train.toarray()\n",
    "X_test = bow_test.toarray()\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZFVl1c97K3z4"
   },
   "source": [
    "Adesso abbiamo i nostri array per addestramento e test ! Standardizziamoli utilizzando la classe *StandardScaler* di sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "UzEYumlq2D0D",
    "outputId": "b8ef3556-6a85-4fad-99ca-c39cbed707fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nznJchb5L-zC"
   },
   "source": [
    "e creiamo il modello di regressione logistica, cerchiamo di ridurre un probabile 'overfitting impostando il parametro C ad un valore piccolo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "mkkLg-MX-zoJ",
    "outputId": "06a1451c-a4f7-41af-8b3c-1309971712b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=0.001)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "otjc9_kDMHxO"
   },
   "source": [
    "Verifichiamo il risultato calcolando l'accuracy e la log loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "y3IJDsVp-7PC",
    "outputId": "d89ed6f7-35d1-4fbb-8c57-5a55470f2fc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 0.9432 - Train Loss 0.1975\n",
      "Test Accuracy 0.8772 - Test Loss 0.3125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "train_pred = lr.predict(X_train) \n",
    "train_pred_proba = lr.predict_proba(X_train)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_pred)\n",
    "train_loss = log_loss(y_train, train_pred_proba)\n",
    "\n",
    "test_pred = lr.predict(X_test)\n",
    "test_pred_proba = lr.predict_proba(X_test)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, test_pred)\n",
    "test_loss = log_loss(y_test, test_pred_proba)\n",
    "\n",
    "print(\"Train Accuracy %.4f - Train Loss %.4f\" % (train_accuracy, train_loss)) \n",
    "print(\"Test Accuracy %.4f - Test Loss %.4f\" % (test_accuracy, test_loss)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u6XSuNbsMe90"
   },
   "source": [
    "Senza alcuna sorpresa, il risultato è lo stesso di prima, ma stavolta abbiamo fatto tutto noi :)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R2pIEN-5nrrO"
   },
   "source": [
    "## Mettiamo all'opera il modello\n",
    "Proviamo adesso ad utilizzare il modello per classificare recensioni scritte da noi, per farlo dobbiamo creare le features utilizzando lo stesso oggetto *CountVectorizer* definito sopra per poi passare le features così ottenute al metodo predict del classificatore.<br>\n",
    "Ricorda che 1 equivale alla classe positiva (recensione positiva) e 0 alla classe negativa (recensione negativa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rKOviyjvmoJS",
    "outputId": "eab7eb89-e068-4501-801c-70f59406a4e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"This is the best movie I've ever seen\"\n",
    "lr.predict(bow.transform([review]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MK4kSg3ym9Ok",
    "outputId": "97d86bf6-d83d-4338-bb46-ecfd927867a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"This is the worst movie I've ever seen\"\n",
    "lr.predict(bow.transform([review]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPVM6whfnNzc"
   },
   "source": [
    "**NOTA BENE**\n",
    "Le nuove recensioni di cui vogliamo ottenere le recensioni devono **SEMPRE** subire le stesse trasformazioni che hanno subito le recensioni del set di addestramento, per questo usiamo lo stesso oggetto di prima con il metodo *transform*. Questa è una regola generale del machine learning che si applica qualsiasi sia lo scopo predittivo del nostro modello."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "classifier_sklearn.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
