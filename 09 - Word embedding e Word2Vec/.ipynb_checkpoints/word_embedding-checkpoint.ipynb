{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ProfAI/nlp00/blob/master/09%20-%20Word%20embedding%20e%20Word2Vec/word_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sNb6_Q5_f2vE"
   },
   "source": [
    "## Word embedding\n",
    "Il **Word embedding** è un modello che ci permette di generare una serie di vettori (embedding vectors) ognuno dei quali quantifica una caratteristica delle parole. In questo notebook creeremo una rete neurale artificiale per classsificare recensioni come positive o negative usando il Word Embedding per codificare le recensioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9cSDivbYhDhW",
    "outputId": "85816c17-8127-416d-d852-a2fc5bd260bd"
   },
   "outputs": [],
   "source": [
    "#!pip install numpy==1.16.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LyB8q8Aw1tqp"
   },
   "source": [
    "## Prepariamo i dati\n",
    "In precedenza abbiamo caricato e preprocessato manualmente l'IMDB Movies Review Dataset, in questo caso utilizziamo direttamente il dataset già preprocessato che ci mette a disposizione Keras.\n",
    "<br>**ATTENZIONE**<br>\n",
    "Se caricando il dataset ottieni questo errore:<br>\n",
    "*ValueError: Object arrays cannot be loaded when allow_pickle=False*\n",
    "<br>\n",
    "questo è casuato da un bug nell'ultima versione di keras, per correggerlo esegui il downgrade di numpy usando la cella di codice qui sotto e riavvia il kernel (su Colaboratory seleziona Runtime dalla barra dei comandi e clicca su Restart Runtime)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MP00t5BP3PNL"
   },
   "outputs": [],
   "source": [
    "#!pip install numpy==1.16.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "zVFYLaPrf054",
    "outputId": "aed8a090-3a31-4f2f-9f8e-0eea866111dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 1s 0us/step\n",
      "Numero di esempi nel train set: 25000\n",
      "Numero di esempi nel test set: 25000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import imdb \n",
    "\n",
    "num_words = 10000\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=num_words) \n",
    "#caricare gli array train and test dove si passa solo un argoment: il num max di parole da prendere\n",
    "\n",
    "print(\"Numero di esempi nel train set: %d\" % len(X_train))\n",
    "print(\"Numero di esempi nel test set: %d\" % len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0] #how the corpus has been codified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6jvHkFhC3T30"
   },
   "source": [
    "Ogni riga della lista con le features corrisponde ad una frase, ogni colonna contiene l'indice di una parola all'interno del vocabolario dell'intero corpus di testo. Il vettore con il target contiene un unico valore che può essere 0 per una recensione negativa o 1 per una recensione positiva.<br> \n",
    "Definiamo una funzione che ci permette di ricostruire la frase partendo dagli indici, per farlo abbiamo bisogno del vocabolario che mappa le parole agli indici, possiamo ottenerlo con il metodo **.get_word_index()**.\n",
    "<br>\n",
    "**NOTA BENE**\n",
    "<br>\n",
    "Gli indici delle parole hanno un'offset di 3, quindi per ottenere l'indice corretto per il vocabolario dovremo sottrarre 3 all'indice della parola contenuto nella frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "lddFN1OX52C3",
    "outputId": "f21ae533-fb43-478f-84ef-f5644e55193a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? please give this one a miss br br ? ? and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite ? so all you madison fans give this a miss\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how to get the words from the index\n",
    "word_index = imdb.get_word_index()\n",
    "index_word = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def vec_to_text(x):\n",
    "  \n",
    "  text = [index_word.get(i-3,'?') for i in x] #le prime 3 righe sono per i caratteri speciali --> ricordati di sottrarre 3\n",
    "  return \" \".join(text) \n",
    "  \n",
    "vec_to_text(X_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCvLErNe8aSk"
   },
   "source": [
    "Ovviamente le recensioni avranno lunghezza differente, calcoliamo la lunghezza della più lunga e della più corta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IpphdUrrg-gD",
    "outputId": "fcfca3e4-55af-493f-ce75-e117bf87b61e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La review più lunga ha 2494 parole\n",
      "La review più corta ha 11 parole\n"
     ]
    }
   ],
   "source": [
    "longest_review = max(X_train,key=len)\n",
    "shortest_review = min(X_train,key=len)\n",
    "\n",
    "print(\"La review più lunga ha %d parole\" % len(longest_review))\n",
    "print(\"La review più corta ha %d parole\" % len(shortest_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vec_to_text(longest_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? i wouldn't rent this one even on dollar rental night\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_to_text(shortest_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "02dun4qF3bjU"
   },
   "source": [
    "**NOTA BENE** Per rendere le features un buon input per il nostro modello dobbiamo fare in modo che ogni frase abbia la stessa lunghezza, per farlo possiamo usare la funzione **pad_sequences(text)** di keras, che riduce tutte le frasi ad una lunghezza prefissata troncando quelle troppo lunghe e aggiungendo degli zeri a quelle troppo brevi. Usiamo una lunghezza comune di 50 parole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0NybngBzhRGQ",
    "outputId": "c652169c-e934-47d6-bc5b-1a22297cab8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 50)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "maxlen = 50\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen = maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen = maxlen)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F-M5pPcD1wB2"
   },
   "source": [
    "## Creiamo il modello\n",
    "Possiamo utilizzare l'embedding come se fosse uno strato della nostra rete neurale che verrà anch'esso ottimizzato durante la fase di addestramento. Creiamo la rete aggiungendo al primo strato uno strato di embedding, dopodichè aggiungiamo un'altro strato che utilizza la classe Flatten() di keras per convertire la matrice che contiene la rappresentazione vettoriale di una frase in un vettore, unendo tutte le righe una dietro l'altra. Infine aggiungiamo uno strato di output per eseguire la classificazione binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "colab_type": "code",
    "id": "JiflX3qnhUIq",
    "outputId": "38b4e184-f03b-4061-aed0-274704469fc5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-24 12:04:47.629893: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 50, 50)            500000    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2500)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 2501      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 502,501\n",
      "Trainable params: 502,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(num_words, 50, input_length=maxlen)) #num_words: quanto è grande il corpus; 50: quanti tokens/embedding viene codificata la parola\n",
    "#input_len serve per il flatten\n",
    "model.add(Flatten()) #\n",
    "model.add(Dense(1, activation='sigmoid')) #output: reg log\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ueLGoyMK4O7A"
   },
   "source": [
    "Compiliamo il modello e avviamo l'addestramento per 10 epoche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "colab_type": "code",
    "id": "XD6yja5whYuZ",
    "outputId": "91cfc754-6c2c-41d5-e8e2-27b18bcc945e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40/40 [==============================] - 2s 25ms/step - loss: 0.6898 - accuracy: 0.5546 - val_loss: 0.6807 - val_accuracy: 0.6518\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.6397 - accuracy: 0.7794 - val_loss: 0.6108 - val_accuracy: 0.7358\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.5170 - accuracy: 0.8172 - val_loss: 0.5031 - val_accuracy: 0.7756\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.3968 - accuracy: 0.8566 - val_loss: 0.4446 - val_accuracy: 0.7968\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.3189 - accuracy: 0.8910 - val_loss: 0.4179 - val_accuracy: 0.8076\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.2631 - accuracy: 0.9168 - val_loss: 0.4057 - val_accuracy: 0.8120\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.2181 - accuracy: 0.9380 - val_loss: 0.4041 - val_accuracy: 0.8092\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.1797 - accuracy: 0.9569 - val_loss: 0.4064 - val_accuracy: 0.8088\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.1469 - accuracy: 0.9704 - val_loss: 0.4110 - val_accuracy: 0.8100\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.1194 - accuracy: 0.9819 - val_loss: 0.4185 - val_accuracy: 0.8046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe9933af7c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=512, validation_split=0.2, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "-JXeWNcxhfrd",
    "outputId": "61b5b9c2-936c-47c5-b4c5-446ca0b37cdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4065 - accuracy: 0.8163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40650856494903564, 0.81632000207901]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q1LAyqsu1zs4"
   },
   "source": [
    "## Otteniamo gli embedding\n",
    "Se volessimo conoscere gli embedding che il modello genera per una determinata frase possiamo farlo creando un nuovo modello che da in output l'output dell'embedding che abbiamo addestrato. Keras ci da la possibilità di accedere ai singoli strati di un modello utilizzato l'attributo *.layers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qTPAimqL5NZq",
    "outputId": "d87a8aac-95af-4360-d5e5-af4e4f5ea661"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x7fe99339a970>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "meavLoRp5Qg0"
   },
   "source": [
    "Utilizzando le API Funzionali di Keras (ne parleremo più avanti) possiamo creare un modello che prende in input lo stesso input del modello addestrato e da in output l'output dell'embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dqGhALMG06Y0"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "embedding_model = Model(inputs=model.input, outputs=model.layers[0].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ZpItTpc5fIt"
   },
   "source": [
    "Utilizzando il metodo *.predict(x)* otterremo una matrice con la rappresentazione vettoriale di ogni parola della frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "colab_type": "code",
    "id": "eTh6OMit1VJd",
    "outputId": "6c3bb837-106b-473b-a5eb-7d8cbf9fbb2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "x = np.array([X_test[0]]) #trasforma il vettore in matrice\n",
    "\n",
    "x_embedding = embedding_model.predict(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10818409,  0.2400529 ,  0.02922984, -0.2618206 ,  0.00041228,\n",
       "        0.03769689,  0.21158683,  0.14530803, -0.03960946,  0.08206411,\n",
       "        0.13866283,  0.24514107, -0.18515842,  0.18617882,  0.19619426,\n",
       "       -0.18753062,  0.2214797 ,  0.12085671,  0.23491731,  0.21514982,\n",
       "       -0.15531653,  0.18846081,  0.15009934,  0.10126054,  0.19822972,\n",
       "       -0.02158733,  0.10733441, -0.14228767,  0.18018241, -0.24326003,\n",
       "       -0.14856496, -0.0274841 , -0.01437016, -0.20739764,  0.19235584,\n",
       "       -0.19893922, -0.15900247,  0.14390792,  0.22292428, -0.1987068 ,\n",
       "       -0.2027252 ,  0.13500232, -0.12476611, -0.01149696, -0.20824231,\n",
       "        0.01649007,  0.05155145,  0.06319932,  0.0984876 ,  0.15467629],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embedding[0]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "word_embedding.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
